# 性能测试方法 

​	性能测试有四个原则：测试真实应用，理解批处理流逝时间、吞吐量和响应时间，用统计方法应对性能的变化，尽早频繁测试。

​	性能分析有两种方法，自顶向下和自底向上。自顶向下是最常见的性能调优方法首先从应用本身进行监控如操作系统、JVM、Java EE容器以及应用性能测试统计指标。自底向上从不同平台(指底层 CPU架构和CPU数量不同)上进行性能调优，在无法优化源代码的情况下，通过收集和监控最底层CPU的性能统计数据将应用迁移到其它操作系统来进行性能上的优化。个人认为在云服务时代和容器化的情况下，更多需要关心这些的是厂商对PASS层的优化。作为Java程序员则关心的是JIT在不同平台下的性能差异和优化少许操作系统如CPU调度算法、磁盘IO、网络等一系列问题。 



## 1. 测试真实应用

​	性能测试应该在实际的使用环境中进行性能测试，测试的方法可以分为三种，只有适用实际应用才能取得最好的测试效果。
### 1.1 微基准测试

​	微基准测试用例测试微小代码单元的性能，包括同步方法和异步方法的用时比较、创建线程和使用线程的代价、执行某种算法和替代算法实现的耗时等等。

```java
public void doTest{
    double num;
    long then = System.currentTimeMillis();
    for (int i = 0; i < nLoops; i++){
        num = fibImpl(100);
    }
    long now = System.currentTimeMillis();
    System.out.print("Elapsed time :" + (now - then))
}

```

微基准测试需要考虑三个问题：

1. ​	必须使用被测的结果，可以通过把局部变量实例变量并使用volatile避免JVM同步代码在线程数增加时线程竞争而导致测试结果成为受JVM性能影响的JVM性能测试。

2. ​	不要包括无关的操作，编译器会对一直多余的如迭代操作做智能优化，为了避免这种优化而造成测试结果无意义。
3. ​        必须输入合理的参数，如随机参数对测试结果无代表性，因此我们需要对实际场景进行优化。

### 总结： 微基准测试的比较难于编写代码，并且即使写了，真正管用的非常有限；所以在实际的开发和性能调优的选择上，必须了解了所有的隐患之后，再选择是不是现则微基准测试。

#### tips：
  Java中可以使用JMH来做微基准测试，参考 [JMH详解](jmh.md)

### 1.2 宏基准测试

​	衡量性能的最好事物就是应用本身，以及它所用到的外部资源，使应用本身基于真实环境中的测试。测试方式在互联网中常见有模拟生产环境侧试、全链路测试。从每个模块或子系统中找出影响RPS的算法或资源，如数据库每秒只能处理100个RPS而其它模块都能处理100个甚至更多，则优化的重点在于数据库。

### 总结： 优化业务处理并不完全浪费时间，但是要考虑优先顺序 ，不进行整体应用测试就不可能知道那部分优化会产生回报。

### 1.3 介基准测试

​	介于微基准测试和宏基准测试，进行不完整应用的基准测试，较微基准测试隐患更少，比宏基准测试容易，更容易出现线程化更容易出现同步瓶颈。

### 总结：介基准测试有利于自动化测试，特别是模块化测试或操作级别隔离性能，相对于宏基准测试是一种合理的折中测试途径，但不是替代方法。

## 2. 理解批处理流逝时间、吞吐量和响应时间

​	以多视角审视应用性能，应该测量哪个指标取决于对应用最重要的因素。

### 2.1 批处理流逝时间

​	应用记下时间点从而测量执行时间，但在Java中由于JIT需要编译并优化，所以Java性能测试要考虑代码优化的热身期，应该在运行代码执行足够长时间已经编译并优化之后再测量性能。另外还需要考虑如JPA缓存等因素。

### 2.2 吞吐量测试

​	吞吐量测试是基于一段时间内所能完成的工作量，通常指每秒完成的操作量，常用指标有每秒事务数(TPS)、每秒请求数(RPS)、每秒操作次数(OPS)。

### 2.3 响应时间测试

​	从客户端发送请求至收到响应之间的流逝时间，服务器的效率取决于它的响应固定负载有多快。

​	衡量响应时间有两种方法，通过平均值：请求时间的总和除以请求数。通过百分位请求，例如第百分之90响应时间。两者区别在于 平均值受离散值影响，离散值越大堆平均响应时间影响会越大。

## 3. 用统计方法应对性能的变化

​	通过代码基线(baseline)、试样(specimen)比较性能差异，正确判断测试结果间差异是否需要进行统计分析，通过统计分析才能确定这些差异是不是归因于随机因素。
​	可以用严谨的t检验比较测试结果，实现上述目的。
​	t检验可以告知我们变动存在的概率，但无法告诉我们那种变动该忽略而哪种该追查，难点在于如何找到平衡，也是性能调优工程的艺术魅力。

## 4. 尽早频繁测试
​	在考虑开发周期的情况下可以考虑尽早频繁测试可以有助于更早捕获和解决性能衰减，但是也会要考虑代码是否需要频繁改动。
遵循自动化一切、测试一切、在真实系统上运行可以使尽早频繁测试变得更有效。

## 小结：

- 性能测试包括各种权衡，面对诸多相互制约的选择，我们应该做出适当的决策对于系统性能能否提升至关重要。
- 性能测试应该先测试哪部分与我们的经验和直觉息息相关，所有测试都有某方面的价值。
- 那些代码造成性能衰减我们并不能总是皂白分明，程序不时会出现随机性，所以统计分析有助于是结果变得更加客观，理解这些数据背后的概率及其意义有助于降低主观性。

​	


